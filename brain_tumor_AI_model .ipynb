{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNU1XQDKiJz7"
      },
      "source": [
        "**<center><font size=5>Vizuara AI Labs: Build your brain tumor AI model</font></center>**\n",
        "***\n",
        "\n",
        "\n",
        "**Table of Contents**\n",
        "- <a href='#intro'>1. Project Overview and Objectives</a>\n",
        "    - <a href='#dataset'>1.1. Data Set Description</a>\n",
        "    - <a href='#tumor'>1.2. What is Brain Tumor?</a>\n",
        "- <a href='#env'>2. Setting up the Environment</a>\n",
        "- <a href='#import'>3. Data Import and Preprocessing</a>\n",
        "- <a href='#cnn'>4. Building the AI model</a>\n",
        "- <a href='#cnn'>5. Model evaluation</a>\n",
        "- <a href='#concl'>6. Testing the model</a>\n",
        "- <a href='#concl'>7. Conclusion</a>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOFmp8VgiS76"
      },
      "source": [
        "# Introduction\n",
        "Welcome to the Vizuara AI Labs project notebook. This guide is designed to help you build your own machine learning model for medical imaging diagnosis, starting with brain tumor detection. The structure of this notebook is organized into modular building blocks, allowing you to easily adapt and apply this workflow to other projects, such as heart disease classification, by modifying specific sections."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKyw9ku8ifnr"
      },
      "source": [
        "# <a id='intro'>1. Project Overview and Objectives</a>\n",
        "\n",
        "The main purpose of this project was to build a CNN model that would classify if subject has a tumor or not base on MRI scan.\n",
        "\n",
        "## <a id='dataset'>1.1. Data Set Description</a>\n",
        "\n",
        "The image data that was used for this problem is [Brain MRI Images for Brain Tumor Detection](https://www.kaggle.com/navoneel/brain-mri-images-for-brain-tumor-detection). It conists of MRI scans of two classes:\n",
        "\n",
        "* `NO` - no tumor, encoded as `0`\n",
        "* `YES` - tumor, encoded as `1`\n",
        "\n",
        "Unfortunately, the data set description doesn't hold any information where this MRI scans come from and so on.\n",
        "\n",
        "## <a id='tumor'>1.2. What is Brain Tumor?</a>\n",
        "\n",
        "> A brain tumor occurs when abnormal cells form within the brain. There are two main types of tumors: cancerous (malignant) tumors and benign tumors. Cancerous tumors can be divided into primary tumors, which start within the brain, and secondary tumors, which have spread from elsewhere, known as brain metastasis tumors. All types of brain tumors may produce symptoms that vary depending on the part of the brain involved. These symptoms may include headaches, seizures, problems with vision, vomiting and mental changes. The headache is classically worse in the morning and goes away with vomiting. Other symptoms may include difficulty walking, speaking or with sensations. As the disease progresses, unconsciousness may occur.\n",
        ">\n",
        "> ![](https://upload.wikimedia.org/wikipedia/commons/5/5f/Hirnmetastase_MRT-T1_KM.jpg)\n",
        ">\n",
        "> *Brain metastasis in the right cerebral hemisphere from lung cancer, shown on magnetic resonance imaging.*\n",
        "\n",
        "Source: [Wikipedia](https://en.wikipedia.org/wiki/Brain_tumor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzb8Tvybf2mD"
      },
      "source": [
        "\n",
        "# <a id='intro'>2. Setting up the Environment: Import Statements</a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "id": "MEtuVaY6f2mF",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('dark_background')\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EklzUuiXf2mG"
      },
      "source": [
        "# <a id='intro'>3(a) Data Import</a>\n",
        "\n",
        "When working on different projects, you will need to load a different dataset. The best way to load a dataset is as follows:\n",
        "\n",
        "(a) Upload the dataset to Google Drive\n",
        "\n",
        "(b) The image path will be `/content/drive/My Drive/name_of_your_dataset`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFj7sqS-gAw1",
        "outputId": "33616936-6a79-4d7f-c8d0-17687e9ba5aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkHp8jy5Yn4-"
      },
      "source": [
        "# <a id='intro'>3(b) Data Processing</a>\n",
        "\n",
        "1. First, we create a data list for storing image data in numpy array form\n",
        "2. Secondly, we create a paths list for storing paths of all images\n",
        "3. Thirdly, we create result list for storing one hot encoded form of target class whether normal or tumor\n",
        "\n",
        "The label 0 is transformed into [1, 0] (one-hot encoding).\n",
        "\n",
        "The label 1 is transformed into [0, 1] (one-hot encoding)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "O0wV4lRmf2mG",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# This cell updates result list for images with tumor\n",
        "\n",
        "data = []\n",
        "paths = []\n",
        "result = []\n",
        "\n",
        "for r, d, f in os.walk(r'/content/drive/My Drive/brain_tumor_dataset/yes'):\n",
        "    for file in f:\n",
        "        if '.jpg' in file:\n",
        "            paths.append(os.path.join(r, file))\n",
        "\n",
        "for path in paths:\n",
        "    img = Image.open(path)\n",
        "    img = img.resize((128,128))\n",
        "    img = np.array(img)\n",
        "    if(img.shape == (128,128,3)):\n",
        "        data.append(np.array(img))\n",
        "        result.append(encoder.transform([[0]]).toarray())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "3gHbYkMyf2mH",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# This cell updates result list for images without tumor\n",
        "\n",
        "paths = []\n",
        "for r, d, f in os.walk(r\"/content/drive/My Drive/brain_tumor_dataset/no\"):\n",
        "    for file in f:\n",
        "        if '.jpg' in file:\n",
        "            paths.append(os.path.join(r, file))\n",
        "\n",
        "for path in paths:\n",
        "    img = Image.open(path)\n",
        "    img = img.resize((128,128))\n",
        "    img = np.array(img)\n",
        "    if(img.shape == (128,128,3)):\n",
        "        data.append(np.array(img))\n",
        "        result.append(encoder.transform([[1]]).toarray())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOjTinkQf2mH",
        "outputId": "d315af2b-cbec-49cb-8d32-a411767c80a3",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(139, 128, 128, 3)"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = np.array(data)\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2us8AzNbks5T",
        "outputId": "0c4b7d64-1e67-404c-a270-bd1d15c6e5d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of images we have: 139\n"
          ]
        }
      ],
      "source": [
        "print(f'Total number of images we have: {len(data)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "8o03PVTpf2mH",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "result = np.array(result)\n",
        "result = result.reshape(139,2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seqqfDZUf2mH"
      },
      "source": [
        "## <a id='intro'>3.1. Splitting the data into training and testing</a>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "KQKoUzzXf2mH",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(data, result, test_size=0.2, shuffle=True, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVf6j9BkkY2O",
        "outputId": "5c829d93-f4b2-480b-c69e-9692c5c7795e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of images in training data: 111\n"
          ]
        }
      ],
      "source": [
        "print(f'Number of images in training data: {len(x_train)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ed3qC8LzkmnB",
        "outputId": "7b75e86f-bbc9-4f14-b556-6f7a30634bfa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of images in testing data: 28\n"
          ]
        }
      ],
      "source": [
        "print(f'Number of images in testing data: {len(x_test)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sB4R2DrOf2mH"
      },
      "source": [
        "# <a id='intro'>4. Building the AI model</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQm07qElf2mH"
      },
      "source": [
        "## <a id='dataset'>4.1. Model Description</a>\n",
        "\n",
        "In this step, we are constructing an AI model that uses a Convolutional Neural Network (CNN), which is particularly good for image recognition tasks. Our model begins with two convolutional layers that have 32 filters each; these layers are designed to detect basic patterns in the brain MRI images, like edges and textures.\n",
        "\n",
        "## <a id='dataset'>4.2 Batch normalization</a>\n",
        "\n",
        "\n",
        "We apply batch normalization after the convolutional layers to accelerate training by scaling the outputs to a standard range.\n",
        "\n",
        "## <a id='dataset'>4.3 Pooling</a>\n",
        "\n",
        "Next, we introduce a pooling layer to reduce the dimensionality of the data, which helps the model to focus on the important features, and a dropout layer to prevent overfitting, which is when the model learns the training data too well and performs poorly on new data. We repeat this pattern of convolutional, batch normalization, pooling, and dropout layers with 64 filters in the convolutional layers to capture more complex patterns.\n",
        "\n",
        "## <a id='dataset'>4.4 Fully connected layer</a>\n",
        "\n",
        "After processing through these layers, the data is flattened into a one-dimensional array so it can be fed into densely connected layers, which will make the final decisions about what the patterns represent â€“ in our case, whether there is a tumor or not.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 165566,
          "sourceId": 377107,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30042,
      "isGpuEnabled": false,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
